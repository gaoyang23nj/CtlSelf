\section{Optimal Detection}
\label{sec:opt_detect}
\subsection{Problem Formulation}
Assume that the detection can be conducted.
The detection rate is $U(t)$, $0 \le U(t) \le U_{m}$.
$U_{m}$ is the limitation of the detection rate, which is the constraint from the hardware and the time sequences.
Then, the ODEs can be reformulated as
\begin{small}
\begin{equation}
\label{eq:SIM_t}
%\nonumber
\begin{aligned}
\frac{\mathrm{d} I(t)}{\mathrm{d} t} &=
\lambda (N-I(t)) - \rho I(t), \\
\frac{\mathrm{d} D(t)}{\mathrm{d} t} &=
\rho I(t)  - \lambda D(t) - \frac{D(t)}{N} U(t),\\
\frac{\mathrm{d} R(t)}{\mathrm{d} t} &=
- \beta (N-I(t)-D(t)) + \frac{D(t)}{N} U(t).
\end{aligned}
\end{equation}
\end{small}
Meanwhile,
\begin{small}
\begin{equation}
\label{eq:SIM_0}
%\nonumber
\begin{aligned}
I(0)=0,\\
D(0)=0,\\
R(0)=N.
\end{aligned}
\end{equation}
\end{small}

Thus $I(t)$ is the same with that in the situation without detection, which is
\begin{small}
\begin{equation}
%\nonumber
\label{eq:I}
\begin{aligned}
I(t) = \frac{ \lambda N }{ \lambda + \rho }(1- e^{-(\lambda + \rho)t}).
\end{aligned}
\end{equation}
\end{small}

Considering that the detection is also the cost,
the object function will be
\begin{small}
\begin{equation}
\nonumber
\begin{aligned}
J &= \int_{0}^{T} (1-\alpha) D + \alpha U dt.
\end{aligned}
\end{equation}
\end{small}
Here $\alpha$ is the weight, which can control the importance
between the cost of selfish relay nodes
and detections.
Thus $0 < \alpha < 1$.
Similar with the previous section,
$I(t)$ and $D(t)$ is the state functions.
$U(t)$ is the controllable variable, $0 \le U(t)\ \le U_{m}$.

\subsection{Optimal Control by Pontryagin's Maximum Principle}
Now we utilize the Pontryagin's maximal principle~\cite{DBLP:journals/tcss/WuDH18}
to find the optimal $U(t)$, which will minimize the total cost.
First, the Hamilton function is
\begin{small}
\begin{equation}
\nonumber
\begin{aligned}
H =& (1-\alpha) D + \alpha U + \lambda_{I} (\lambda (N-I) - \rho I) \\
& + \lambda_{D} (\rho I  - \lambda D - \frac{D}{N} U) \\
%=& (1-\alpha) M + \alpha U + \lambda_{1} (\beta (N-I) - \rho I) + \lambda_{2} \rho I\\
%& - \beta \lambda_{2} M - \lambda_{2} \frac{1}{N} U M \\
=& (1-\alpha) D + \lambda_{I} (\lambda (N-I) - \rho I) \\
& + \lambda_{D} (\rho I  - \lambda D) + ( \alpha - \lambda_{D} \frac{D}{N}) U.
\end{aligned}
\end{equation}
\end{small}
Note that $\lambda_{I}$ and $\lambda_{D}$ denote two co-state functions.
Without the final constraint, the terminal condition is
$\lambda_{I}(T) = 0$ and $\lambda_{D}(T) = 0$.
Then the adjoint function is
\begin{small}
\begin{equation}
\nonumber
\begin{aligned}
\dot{\lambda_{D}} = - \frac{ \partial H}{ \partial D}
= \lambda_{D} (\lambda + \frac{U}{N} ) - (1-\alpha).
\end{aligned}
\end{equation}
\end{small}

Thus
\begin{small}
\begin{equation}
\label{eq:opt_U}
%\nonumber
U^{*}(t) =
\left\{
\begin{aligned}
&0,      & \text{if }  \alpha - \lambda_{D} \frac{D}{N} \ge 0 \\
&U_{m},        & \text{if } \alpha - \lambda_{D} \frac{D}{N} < 0
\end{aligned}
\right.
\end{equation}
\end{small}

In summary, we have the ODE functions $\dot{D}$, $\dot{\lambda_{D}}$,
the initial condition $D(0)=0$ and the boundary condition $\lambda_{D}(T)=0$,
Thus the problem is to solve a BVP problem,
which is
\begin{small}
\begin{equation}
\label{eq:bvp}
\begin{aligned}
\dot{D} &= - (\lambda + \frac{U^{*}}{N}) D + \rho I,\\
\dot{\lambda_{D}} &= (\lambda + \frac{U^{*}}{N} ) \lambda_{D} - (1-\alpha),\\
\end{aligned}
\end{equation}
\end{small}
where $D(0) = 0$ and $\lambda_{D}(T) = 0$.
We can solve the BVP problem with the shooting method by the bvpSolve package of R.
The whole algorithm are shown in Alg.~\ref{alg:opt_detection},
where $\delta t$ presents the time granularity.
The message replication time and the state switching time are recorded by $src$.
So the reward can also be computed by $src$.
%footnote code link!!!
Then we analyze the properties of the optimal control $U^{*}(t)$.
\begin{algorithm}
\caption{Optimal Selfish Node Detection}
\label{alg:opt_detection}
\begin{small}
\begin{algorithmic}[1]
\REQUIRE $T_{m}$, ${U}_{m}$, $\lambda$, $\rho$, $T$
\STATE {time $t$ $\leftarrow$ $0$}
\STATE {compute the solution of (\ref{eq:bvp})
as the switch-on duration $\mathcal{T}$}
\WHILE {$t \le T$}
    \IF {contact $n_{i}$ without message}
        \STATE {replicate $m$ to $n_{i}$}
        \STATE {state of $n_{i}$ changes to state $I$}
        \STATE {$src$ record $t$ as the message replication time}
    \ENDIF
    \IF {$t$ $\in$ $\mathcal{T}$}
        \STATE {select a relay node $n_{j}$ randomly}
        \STATE {$src$ conduct the selfish node detection to $n_{j}$}
            \IF {$n_{j}$ is detected as a selfish node}
                \STATE {state of $n_{j}$ changes to state $R$}
                \STATE {$src$ record $t$ as the state switching time}
            \ENDIF
    \ENDIF
    \STATE {$t \leftarrow t + \delta t$}
\ENDWHILE
\FOR {$n_{i}$, $1 \le i \le N$}
    \STATE {pay reward to $n_{i}$ based on 
    the time of staying in state $I$}
\ENDFOR
\end{algorithmic}
\end{small}
\end{algorithm}

%BVP Problem: solution exist and unique
%BVP?a¦Ì?¡ä??¨²o¨ª?¡§¨°?D??¡§¨¤¨ª
%\begin{lem}
%There exists a unique solution of (\ref{eq:bvp}).
%\end{lem}
%\begin{proof}
%The solution space is $R: 0 \le t \le T, $
%
%(\ref{eq:bvp}) comforts to the Lipschitz condition.
%Then the solution exists and is unique.(ODE).
%
%Since $D(0) = 0$ and $\le D(t) \le N$,
%$|D(T) - D(0)| \le \frac{N}{T} |T-0|$.
%Thus $D(t)$ comforts to the Lipschitz conduction,
%and the corresponding Lipschitz parameter is $\frac{N}{T}$.
%\end{proof}
\begin{lem}\label{lem:Ut0}
At the beginning and the end of the whole duration,
the optimal control stop the selfish node detection,
which means $U(0)=U(T)=0$.
\end{lem}

\begin{proof}
At the beginning of the duration, $M(0)=0$,
which is the initial condition of \ref{eq:bvp}.
Then $\alpha - \lambda_{D}(0) \frac{D(0)}{N} = \alpha > 0$.
Following (\ref{eq:opt_U}), the optimal $U(0)=0$.

At the end of the duration, $\lambda_{2}(T)=0$,
which is the boundary condition of \ref{eq:bvp}.
Then $\alpha - \lambda_{D}(T) \frac{D(T)}{N} = \alpha > 0$.
Based on (\ref{eq:opt_U}), the optimal $U(T)=0$.
\end{proof}

Based on the differential function $\dot{I}$,
the equilibrium point of $I$ can be obtained from $\dot{I}=0$,
which is $I^{*}=\frac{\lambda N}{\lambda+\rho}$.
When $I(t)<I^{*}$, $I(t)$ will increase 
with $t$ and approach to $\frac{\lambda N}{\lambda+\rho}$.
Meanwhile, in this paper $I(0)=0$ at the beginning of time.
We also note that $I(t)$ will not be effected by
any detection policies.

Based on the differential function $\dot{D}$,
the equilibrium point is obtained from $\dot{D}=0$,
which is $M^{*}=\frac{\rho I}{\beta+\frac{1}{N}U}$.
In the situation without detection,
the equilibrium point is
$D^{*}=\frac{\rho I^{*}}{\beta}=\frac{\rho N}{\beta + \rho}$.
In the situation with full detection,
the equilibrium point is
$D^{*}=\frac{\rho I^{*}}{\beta + \frac{1}{N} U_{m}}
=\frac{\rho}{\beta + \frac{1}{N} U_{m}} \frac{\beta N}{\beta+\rho}$.

Since $\alpha$ is the weight of detecting the selfish nodes,
we can assume that if $\alpha$ is enough high, the detection will not perform according to the optimal control strategy.
\begin{lem}\label{lem:alpha}
If $\alpha \ge \alpha_{th}$, the optimal control let the detection stop in the whole duration,
namely $U(t)=0$, $0 \le t \le T$.
\end{lem}

\begin{proof}
Assume that $\rho$, $N$, $\beta$ is given.
Let $W(t) = \lambda_{D}(t)D(t)$.
\begin{small}
\begin{equation}
%\nonumber
\label{eq:W_diff}
\begin{aligned}
W^{'}(t) =& D^{'}(t) \lambda_{D}(t) + D(t) \lambda_{D}^{'}(t)\\
=& \left(\rho I(t)  - \lambda D(t)
- \frac{D(t)}{N} U(t) \right)\lambda_{D}(t) \\
&+ D(t) \left(\lambda_{D}(t) \left( \lambda + \frac{U(t)}{N} \right)
- (1-\alpha) \right)\\
=& \rho \lambda_{D}(t) I(t) - (1-\alpha)D(t).
\end{aligned}
\end{equation}
\end{small}
Based on (\ref{eq:opt_U}),
we can find that the switching time $t$ is determined by
whether $\lambda_{D}(t)D(t) \le \alpha N$.
Since $D(0)=0$ and $\lambda_{D}(T)=0$,
$W(0)=W(T)=0<\alpha N$.

Now we focus on the poles of $W(t)$, namely $t^{*}$,
where $W^{'}(t^{*})=\rho \lambda_{D}(t^{*}) I(t^{*})
- (1-\alpha)D(t^{*})=0$.
Then $D(t^{*}) = \frac{\rho \lambda_{D}(t^{*}) I(t^{*})}{1-\alpha}$.
\begin{small}
\begin{equation}
%\nonumber
\label{eq:W_t_star}
\begin{aligned}
W(t^{*}) &= \lambda_{D}(t^{*}) D(t^{*})
= \frac{\rho I(t^{*}) \lambda_{D}(t^{*})^2}{1-\alpha}.
\end{aligned}
\end{equation}
\end{small}

According to $\dot{\lambda_{D}}$ in (\ref{eq:bvp}),
the equilibrium point of $\lambda_{D}$
is that $\lambda_{D}^{*} = \frac{1-\alpha}{\lambda+\frac{U}{N}}$.
Since $0 \le U \le U_{m}$, 
$0 < \frac{1-\alpha}{\lambda+\frac{U_{m}}{N}} 
\le \lambda_{D}^{*} \le \frac{1-\alpha}{\lambda}$.
Note $\lambda_{D}(T)=0$.
Based on the phase line in ODE for $\dot{\lambda_{D}}$,
$\lambda_{D}(t)$ decreases with $t$ when
$\lambda_{D}(t) < \lambda_{D}^{*}$.
Conversely, $\lambda_{D}(t)$ increases with $t$
when $\lambda_{D}(t) > \lambda_{D}^{*}$.
Thus $0 \le \lambda_{D}(t) \le \lambda_{D}^{*} 
\le \frac{1-\alpha}{\lambda}$ when $0 \le t \le T$.
Additionally, $0 \le I(t) \le \frac{\lambda N}{\lambda + \rho}$.
From (\ref{eq:W_t_star}), we can derive that 
the upper boundary of $W(t)$, $W_{up}$, which is
\begin{small}
\begin{equation}
\nonumber
\begin{aligned}
W(t) \le W(t^{*}) \le \frac{\rho}{1-\alpha} 
\frac{\lambda N}{\lambda + \rho} (\frac{1-\alpha}{\lambda})^2 
= \frac{\rho N (1-\alpha)}{\lambda(\lambda+\rho)} = W_{up}.
\end{aligned}
\end{equation}
\end{small}

Assume that $\alpha$ can satisfy that $W_{up} \le \alpha N$,
which means that 
$\alpha \ge 
\frac{\rho}{\lambda(\lambda+\rho)+\rho}
= \alpha_{th}$.
Then $W(t) \le \alpha N$, when $0 \le t \le T$.
Therefore the optimal control $U^{*}(t) \equiv 0$,
when $0 \le t \le T$ in this situation.
\end{proof}
